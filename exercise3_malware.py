import pandas as pd
import numpy as np
import time
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from data.sample_data import create_malware_dataset

def run_exercise3():
    print("\n" + "=" * 60)
    print("EXERCICE 3: CLASSIFICATION DE MALWARE")
    print("=" * 60)
    
    # √âtape 3.1 : Cr√©ation du dataset
    print("\n--- √âtape 3.1 : Cr√©ation du dataset ---")
    df_malware = create_malware_dataset()
    
    print("Aper√ßu du dataset :")
    print(df_malware.head())
    
    print("\nDistribution des classes :")
    print(df_malware['label'].value_counts())
    
    print("\nStatistiques par classe :")
    print(df_malware.groupby('label').mean())
    
    # Question 3.1
    print(f"\nüìä QUESTION 3.1:")
    print("Caract√©ristiques discriminantes:")
    print("- file_size: les malwares sont g√©n√©ralement plus gros")
    print("- entropy: plus √©lev√©e pour les malwares (chiffrement/compression)")
    print("- num_imports: plus d'imports pour les malwares")
    print("- has_signature: moins de signatures pour les malwares")
    
    # √âtape 3.2 : Pr√©paration des donn√©es
    print("\n--- √âtape 3.2 : Pr√©paration des donn√©es ---")
    
    X = df_malware.drop('label', axis=1)
    y = df_malware['label']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=42, stratify=y
    )
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"Taille ensemble d'entra√Ænement : {len(X_train)}")
    print(f"Taille ensemble de test : {len(X_test)}")
    
    # Question 3.2
    print(f"\nüìä QUESTION 3.2:")
    print("stratify=y pr√©serve la proportion des classes dans train/test.")
    print("La normalisation est importante pour les algorithmes sensibles aux √©chelles (SVM).")
    
    # √âtape 3.3 : Comparaison de mod√®les
    print("\n--- √âtape 3.3 : Comparaison de mod√®les ---")
    
    models = {
        'Decision Tree': DecisionTreeClassifier(random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'SVM': SVC(kernel='rbf', random_state=42)
    }
    
    results = []
    
    for name, model in models.items():
        print(f"\n{'='*50}")
        print(f"Entra√Ænement : {name}")
        print('='*50)
        
        start_time = time.time()
        model.fit(X_train_scaled, y_train)
        training_time = time.time() - start_time
        
        y_pred = model.predict(X_test_scaled)
        
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        
        results.append({
            'Mod√®le': name,
            'Accuracy': accuracy,
            'Precision': precision,
            'Recall': recall,
            'F1-Score': f1,
            'Temps (s)': training_time
        })
        
        print(f"Accuracy : {accuracy:.4f}")
        print(f"Precision : {precision:.4f}")
        print(f"Recall : {recall:.4f}")
        print(f"F1-Score : {f1:.4f}")
        print(f"Temps : {training_time:.4f}s")
    
    df_results = pd.DataFrame(results)
    print("\n" + "="*70)
    print("COMPARAISON DES MOD√àLES")
    print("="*70)
    print(df_results.to_string(index=False))
    
    # Question 3.3
    print(f"\nüìä QUESTION 3.3:")
    print("Random Forest offre g√©n√©ralement le meilleur compromis performance/temps.")
    print("Recommand√© en production pour sa robustesse et bonnes performances.")
    
    # √âtape 3.4 : Features importantes
    print("\n--- √âtape 3.4 : Analyse des features importantes ---")
    
    rf_model = models['Random Forest']
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nImportance des features :")
    print(feature_importance)
    
    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')
    plt.xlabel('Importance')
    plt.ylabel('Feature')
    plt.title('Importance des features pour la classification de malware')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig('results/feature_importance_malware.png', dpi=300, bbox_inches="tight")
    plt.show()
    
    print("\n‚úì Graphique sauvegard√© dans 'results/feature_importance_malware.png'")
    
    # Question 3.4
    print(f"\nüìä QUESTION 3.4:")
    print(f"Feature la plus importante: {feature_importance.iloc[0]['feature']}")
    print("Coh√©rent avec les observations initiales.")
    print("Ces informations peuvent guider la s√©lection de features pour am√©liorer le mod√®le.")
    
    # √âtape 3.5 : Matrice de confusion
    print("\n--- √âtape 3.5 : Analyse des erreurs ---")
    
    best_model = models['Random Forest']
    y_pred_best = best_model.predict(X_test_scaled)
    
    cm = confusion_matrix(y_test, y_pred_best)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',
                xticklabels=['B√©nin', 'Malware'],
                yticklabels=['B√©nin', 'Malware'])
    plt.title('Matrice de confusion - Classification de malware')
    plt.ylabel('Vraie classe')
    plt.xlabel('Classe pr√©dite')
    plt.tight_layout()
    plt.savefig('results/confusion_matrix_malware.png', dpi=300, bbox_inches="tight")
    plt.show()
    
    errors = X_test[y_test != y_pred_best]
    false_positives = ((y_test == 0) & (y_pred_best == 1)).sum()
    false_negatives = ((y_test == 1) & (y_pred_best == 0)).sum()
    
    print(f"\nNombre d'erreurs : {len(errors)}")
    print(f"Taux d'erreur : {len(errors) / len(y_test) * 100:.2f}%")
    print(f"\nFaux positifs (b√©nin class√© comme malware) : {false_positives}")
    print(f"Faux n√©gatifs (malware class√© comme b√©nin) : {false_negatives}")
    
    # Question 3.5
    print(f"\nüìä QUESTION 3.5:")
    print("Les faux n√©gatifs sont les plus probl√©matiques (malware non d√©tect√©).")
    print("Strat√©gies: augmenter le recall, collecter plus de donn√©es, features additionnelles")
